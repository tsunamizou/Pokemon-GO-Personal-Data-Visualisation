{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f64393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from timezonefinder import TimezoneFinder\n",
    "import pytz\n",
    "from geopy.distance import geodesic\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw pokestop spin data comes in csv batches\n",
    "\n",
    "dfs = [\n",
    "    pd.read_csv('Pokestop_spin1.csv'),\n",
    "    pd.read_csv('Pokestop_spin2.csv'),\n",
    "    pd.read_csv('Pokestop_spin3.csv'),\n",
    "    pd.read_csv('Pokestop_spin4.csv')\n",
    "]\n",
    "\n",
    "pokestops_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "# convert timestamp field into utc-based datetime\n",
    "\n",
    "pokestops_all['Timestamp'] = pd.to_datetime(\n",
    "    pokestops_all['Timestamp'],\n",
    "    utc=True,\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Round fort coordinates as this will be used in map viz\n",
    "\n",
    "pokestops_all['Fort_Latitude'] = pokestops_all['Fort_Latitude'].round(6)\n",
    "pokestops_all['Fort_Longitude'] = pokestops_all['Fort_Longitude'].round(6)\n",
    "\n",
    "\n",
    "# deduplication step 1\n",
    "\n",
    "pokestops = pokestops_all.drop_duplicates(\n",
    "    subset=['Timestamp', 'Fort_Latitude', 'Fort_Longitude']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d345bb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2988 entries with duplicate timestamps\n",
      "Unique timestamps affected: 1492\n"
     ]
    }
   ],
   "source": [
    "# deduplication step 2: identify the double/multi-spins that happened at the same time\n",
    "duplicates = pokestops[pokestops.duplicated(subset=['Timestamp'], keep=False)].sort_values('Timestamp')\n",
    "print(f\"Found {len(duplicates)} entries with duplicate timestamps\")\n",
    "print(f\"Unique timestamps affected: {duplicates['Timestamp'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc992952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates, keeping first occurrence; not ideal but is the easiest way\n",
    "pokestops = pokestops.drop_duplicates(subset=['Timestamp'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06e0d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pokestops = pokestops.copy()\n",
    "\n",
    "#Determine timezone per row from player coordinates\n",
    "\n",
    "tf = TimezoneFinder()\n",
    "\n",
    "pokestops['player_timezone'] = pokestops.apply(\n",
    "    lambda row: tf.timezone_at(lat=row['Player_Latitude'], lng=row['Player_Longitude']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#Convert UTC Timestamp to local time using the timezone\n",
    "\n",
    "def convert_to_local(row):\n",
    "    if pd.isna(row['player_timezone']):\n",
    "        return row['Timestamp']  # fallback to UTC\n",
    "    tz = pytz.timezone(row['player_timezone'])\n",
    "    return row['Timestamp'].tz_convert(tz)\n",
    "\n",
    "pokestops['Timestamp_local'] = pokestops.apply(convert_to_local, axis=1)\n",
    "\n",
    "# Extract local hour and weekday from each datetime object directly\n",
    "pokestops['hour_local'] = pokestops['Timestamp_local'].apply(lambda x: x.hour if pd.notna(x) else None)\n",
    "pokestops['weekday_local'] = pokestops['Timestamp_local'].apply(lambda x: x.strftime('%A') if pd.notna(x) else None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79ae3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute distance between player and fort\n",
    "pokestops['player_fort_distance_m'] = pokestops.apply(\n",
    "    lambda row: geodesic(\n",
    "        (row['Player_Latitude'], row['Player_Longitude']),\n",
    "        (row['Fort_Latitude'], row['Fort_Longitude'])\n",
    "    ).meters,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#Create unique fort_id\n",
    "pokestops['fort_id'] = pokestops.apply(\n",
    "    lambda row: hashlib.md5(f\"{row['Fort_Latitude']}_{row['Fort_Longitude']}\".encode()).hexdigest(),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95838c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull location information basewd on fort coordinates\n",
    "# Nominatim only supports 1 request per second so caching the result\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from time import sleep\n",
    "import os\n",
    "\n",
    "# Initialize the geocoder\n",
    "geolocator = Nominatim(user_agent=\"pokemon_go_app\")\n",
    "\n",
    "def get_location_info(lat, lon):\n",
    "    try:\n",
    "        sleep(1.1)  # Respect rate limit\n",
    "        location = geolocator.reverse(f\"{lat}, {lon}\", language='en')\n",
    "        if location and location.raw.get('address'):\n",
    "            address = location.raw['address']\n",
    "            city = address.get('city') or address.get('town') or address.get('village') or address.get('municipality')\n",
    "            country = address.get('country')\n",
    "            return {'city': city, 'country': country, 'address':address}\n",
    "        else:\n",
    "            return {'city': None, 'country': None, 'address':None}\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {lat}, {lon}: {e}\")\n",
    "        return {'city': None, 'country': None, 'address': None}\n",
    "\n",
    "# Check if we have cached results\n",
    "cache_file = 'pokestop_locations_cache.csv'\n",
    "\n",
    "if os.path.exists(cache_file):\n",
    "    print(\"Loading cached location data...\")\n",
    "    location_lookup = pd.read_csv(cache_file)\n",
    "else:\n",
    "    # Get unique coordinates\n",
    "    unique_coords = pokestops[['Fort_Latitude', 'Fort_Longitude']].drop_duplicates()\n",
    "    print(f\"Geocoding {len(unique_coords)} unique locations...\")\n",
    "    \n",
    "    location_data = []\n",
    "    for idx, row in unique_coords.iterrows():\n",
    "        result = get_location_info(row['Fort_Latitude'], row['Fort_Longitude'])\n",
    "        result['Fort_Latitude'] = row['Fort_Latitude']\n",
    "        result['Fort_Longitude'] = row['Fort_Longitude']\n",
    "        location_data.append(result)\n",
    "        \n",
    "        # Optional: Show progress\n",
    "        if (len(location_data)) % 10 == 0:\n",
    "            print(f\"Processed {len(location_data)}/{len(unique_coords)} locations...\")\n",
    "    \n",
    "    location_lookup = pd.DataFrame(location_data)\n",
    "    \n",
    "    # Save to CSV cache\n",
    "    location_lookup.to_csv(cache_file, index=False)\n",
    "    print(f\"Saved {len(location_lookup)} locations to {cache_file}\")\n",
    "\n",
    "# Merge back to original dataframe\n",
    "pokestops = pokestops.merge(\n",
    "    location_lookup,\n",
    "    on=['Fort_Latitude', 'Fort_Longitude'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Added city and country to {len(pokestops)} pokestop records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2323bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a slice of data for map viz demo\n",
    "\n",
    "poke_jp = pokestops[\n",
    "    (pokestops['country'] == 'Japan') &\n",
    "    (pokestops['Timestamp_local'] < pd.Timestamp('2022-12-29 16:00:00', tz='Asia/Tokyo')) \n",
    "     & (pokestops['Timestamp_local'] > pd.Timestamp('2022-12-26', tz='Asia/Tokyo'))\n",
    "].sort_values('Timestamp_local')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07b2f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the processed data\n",
    "\n",
    "pokestops.to_csv('pokestops.csv', index=False, encoding='utf-8')\n",
    "poke_jp.to_csv('hokkaido.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
